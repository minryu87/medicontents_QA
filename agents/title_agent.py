# -*- coding: utf-8 -*-
"""
TitleAgent (ì¹´í…Œê³ ë¦¬/ì§€ì—­/í˜ë¥´ì†Œë‚˜ ë°˜ì˜ Â· ì˜ë£Œê´‘ê³  ì¤€ìˆ˜ Â· ëª¨ë¸ ìì²´ì„ ì •)
- ì…ë ¥: PlanAgent ì‚°ì¶œë¬¼(plan dict ë˜ëŠ” *_plan.json ê²½ë¡œ/ìë™íƒìƒ‰)
- í”„ë¡¬í”„íŠ¸: test_prompt/title_generation_prompt.txt, test_prompt/title_evaluation_prompt.txt (ì—†ìœ¼ë©´ ë‚´ì¥ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
- ëª¨ë¸: Gemini (GEMINI_API_KEY í•„ìš”) â€” JSON ê°•ì¸ íŒŒì‹±/ë¦¬í˜ì–´ í¬í•¨
- ì¶œë ¥: test_logs/{mode}/{YYYYMMDD}/{timestamp}_title.json (ìµœì¢…) + {timestamp}_title_log.json (ë¡œê·¸)

ë™ì‘ ê°œìš”
1) planì„ ìˆ˜ì§‘/ì •ê·œí™” â†’ ì œëª© ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
2) í›„ë³´ Nê°œ ìƒì„±(candidates)
3) í‰ê°€ í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ì´ ìµœì  1ê°œ ì„ íƒ(selected)
4) ìŠ¤í‚¤ë§ˆ/ê·œì¹™ ê²€ì¦ í›„ ì €ì¥
"""

from __future__ import annotations

import os, json, re, ast
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
import time

# -----------------------
# í™˜ê²½ & ëª¨ë¸
# -----------------------
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise RuntimeError("GEMINI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤(.env)")

genai.configure(api_key=GEMINI_API_KEY)

# -----------------------
# ê²½ë¡œ ìœ í‹¸
# -----------------------
GEN_PROMPT_PATH = Path(os.environ.get('AGENTS_BASE_PATH', Path(__file__).parent)) / "utils" / "test_prompt" / "title_generation_prompt.txt"
EVAL_PROMPT_PATH = Path(os.environ.get('AGENTS_BASE_PATH', Path(__file__).parent)) / "utils" / "test_prompt" / "title_evaluation_prompt.txt"

DEF_MODE = "use"


def _today() -> str:
    return datetime.now().strftime("%Y%m%d")


def _now() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def _ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


# -----------------------
# ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸
# -----------------------
class GeminiClient:
    def __init__(self, model: str = "models/gemini-1.5-flash", temperature: float = 0.7, max_output_tokens: int = 2048):
        self.model_name = model
        self.temperature = temperature
        self.max_output_tokens = max_output_tokens
        self.max_retries = 3
        self.retry_delay = 1.0

    def generate(self, prompt: str, temperature: Optional[float] = None) -> str:
        for attempt in range(self.max_retries):
            try:
                m = genai.GenerativeModel(self.model_name)
                resp = m.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=self.temperature if temperature is None else temperature,
                        max_output_tokens=self.max_output_tokens,
                        candidate_count=1,
                        top_p=0.95,
                        top_k=40,
                    ),
                )
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ê²½ë¡œ
                if getattr(resp, "text", None):
                    return resp.text
                # í›„ë³´ íŒŒì¸  ê²½ë¡œ(ë³´ìˆ˜ìš©)
                if getattr(resp, "candidates", None):
                    parts = getattr(resp.candidates[0].content, "parts", [])
                    if parts and getattr(parts[0], "text", ""):
                        return parts[0].text
                raise ValueError("ì‘ë‹µì— text ì—†ìŒ")
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise e
                print(f"âš ï¸ Gemini í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{self.max_retries}): {e}")
                time.sleep(self.retry_delay * (2 ** attempt))


gem = GeminiClient()


# -----------------------
# íŒŒì¼/ê³„íš ë¡œë”©
# -----------------------

def _latest_plan_path(mode: str) -> Optional[Path]:
    day_dir = Path(f"test_logs/{mode}/{_today()}")
    if day_dir.exists():
        # ê°€ì¥ ìµœì‹  *_plan.json
        cands = sorted(day_dir.glob("*_plan.json"))
        if cands:
            return cands[-1]
    root = Path(f"test_logs/{mode}")
    if not root.exists():
        return None
    all_plans = sorted(root.rglob("*_plan.json"))
    return all_plans[-1] if all_plans else None


def load_plan(plan: Optional[Dict[str, Any]] = None, plan_path: Optional[str | Path] = None, mode: str = DEF_MODE) -> Dict[str, Any]:
    if plan is not None:
        plan = dict(plan)
        plan.setdefault("meta", {}).setdefault("source_log", "(provided dict)")
        return plan
    if plan_path:
        p = Path(plan_path)
        if not p.exists():
            raise FileNotFoundError(f"plan íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {p}")
        return json.loads(p.read_text(encoding="utf-8"))
    p = _latest_plan_path(mode)
    if not p:
        raise FileNotFoundError("ìµœì‹  *_plan.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PlanAgent ì‹¤í–‰ì„ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”.")
    data = json.loads(p.read_text(encoding="utf-8"))
    data.setdefault("meta", {}).setdefault("source_log", str(p))
    return data


# -----------------------
# JSON ê°•ì¸ íŒŒì‹±
# -----------------------

def _parse_json(s: str) -> Optional[Dict[str, Any]]:
    if not isinstance(s, str):
        return None
    s = s.strip()
    s = re.sub(r"^```(json)?", "", s).strip()
    s = re.sub(r"```$", "", s).strip()
    try:
        return json.loads(s)
    except Exception:
        pass
    start = s.find("{")
    if start == -1:
        return None
    depth, end = 0, -1
    for i, ch in enumerate(s[start:], start=start):
        if ch == "{":
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0:
                end = i + 1
                break
    if end != -1:
        try:
            return json.loads(s[start:end])
        except Exception:
            pass
    try:
        obj = ast.literal_eval(s[start:end] if end != -1 else s)
        if isinstance(obj, dict):
            return obj
    except Exception:
        return None
    return None


# -----------------------
# í…ìŠ¤íŠ¸ ì •ë¦¬/ê²€ì¦
# -----------------------

FORBIDDEN_PATTERNS = [
    r"\b100%\b", r"ë¬´í†µì¦", r"ì™„ì¹˜", r"ìœ ì¼", r"ìµœê³ ", r"ì¦‰ì‹œ\s*íš¨ê³¼", r"íŒŒê²©", r"ì´ë²¤íŠ¸", r"íŠ¹ê°€",
    r"\d+\s*ì›", r"\d+\s*ë§Œì›", r"ê°€ê²©", r"ì „í™”", r"\bTEL\b", r"http[s]?://", r"www\.",
]


def _clean(s: str) -> str:
    s = re.sub(r"\s+", " ", (s or "")).strip()
    # ì „ê° ê´„í˜¸/ì´ëª¨ì§€ ë“± ê³¼ë„í•œ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°(ê´€ìš©ì  ìµœì†Œ)
    s = re.sub(r"[\u3000-\u303F\uFE10-\uFE1F\uFE30-\uFE4F]", "", s)
    return s


def _len_ok(title: str) -> bool:
    L = len(title)
    return 18 <= L <= 42  # ê¶Œì¥ 22~38, í—ˆìš© í­ 18~42


def _violates_forbidden(title: str) -> bool:
    t = title or ""
    for pat in FORBIDDEN_PATTERNS:
        if re.search(pat, t):
            return True
    return False


def _contains_hospital(title: str, hospital_name: str) -> bool:
    if not hospital_name:
        return False
    # ë³‘ì›ëª… ê·¸ëŒ€ë¡œ í˜¹ì€ ê³µë°± ì œê±° ë§¤ì¹­ ë°©ì§€
    name = re.escape(hospital_name)
    if re.search(name, title):
        return True
    compact = re.sub(r"\s+", "", hospital_name)
    return compact and compact in re.sub(r"\s+", "", title)


# # -----------------------
# # í”„ë¡¬í”„íŠ¸ ë¡œë”© (ì—†ìœ¼ë©´ ë‚´ì¥ í…ìŠ¤íŠ¸ ì‚¬ìš©)
# # -----------------------

# EMBEDDED_GEN_PROMPT = """
# ë‹¹ì‹ ì€ ì¹˜ê³¼ ë¸”ë¡œê·¸ SEO ì œëª© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¨, ì˜ë£Œê´‘ê³ ë²•ì„ ìœ„ë°˜í•˜ì§€ ì•Šë„ë¡ ë³‘ì› í™ë³´ì„± ë¬¸êµ¬ëŠ” ìµœì†Œí™”í•©ë‹ˆë‹¤.
# ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§€ëŠ” 'plan' JSON(PlanAgent ê²°ê³¼)ì„ ë°”íƒ•ìœ¼ë¡œ,
# ë³‘ì›ëª… ë¹„ë…¸ì¶œ ì›ì¹™ì„ ì§€í‚¤ë©´ì„œ ì§€ì—­ ë§¥ë½(ê°€ëŠ¥í•˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ í›„ë°˜ë¶€),
# ì¹´í…Œê³ ë¦¬ í•µì‹¬, í˜ë¥´ì†Œë‚˜ í†¤, ê·¸ë¦¬ê³  7ê°œ ì„¹ì…˜(ì„œë¡ /ë‚´ì›Â·ë°©ë¬¸/ê²€ì‚¬Â·ì§„ë‹¨/ì˜ë£Œì§„ íŒ/ì¹˜ë£Œ ê³¼ì •/ì²´í¬í¬ì¸íŠ¸/ë§ˆë¬´ë¦¬Â·ê²°ê³¼)ì— ë‹´ê¸´ ë‚´ìš©ì„ ë°˜ì˜í•œ
# ì œëª© í›„ë³´ {N}ê°œë¥¼ ë§Œë“¤ê³  ê·¸ì¤‘ ìµœì  1ê°œë¥¼ ì„ íƒí•˜ì„¸ìš”.

# ì œëª© ì‘ì„± ê·œì¹™(ì˜ë£Œê´‘ê³  ì¤€ìˆ˜):
# 1) í•œêµ­ì–´, ê¶Œì¥ 22~38ì. ê³¼ì¥/ë‹¨ì •/ì¹˜ë£Œíš¨ê³¼ ë³´ì¥ í‘œí˜„ ê¸ˆì§€(ì˜ˆ: 100%, ë¬´í†µì¦, ì™„ì¹˜, ìœ ì¼/ìµœê³ , ì¦‰ì‹œ íš¨ê³¼ ë“±).
# 2) ì¹´í…Œê³ ë¦¬ í•µì‹¬ í‚¤ì›Œë“œ 1ê°œëŠ” í¬í•¨í•˜ë˜ ë‚˜ì—´ ê¸ˆì§€(ì˜ˆ: â€œì¶©ì¹˜ì¹˜ë£Œâ€, â€œì‹ ê²½ì¹˜ë£Œâ€, â€œìŠ¤ì¼€ì¼ë§â€ ë“±ì—ì„œ 1ê°œ ì„ íƒ).
# 3) í™˜ì ê´€ì ì—ì„œ êµ¬ì²´ì Â·ì˜ˆìƒ ì´ë“ì´ ë“œëŸ¬ë‚˜ë˜ ë‚šì‹œ ê¸ˆì§€.
# 4) ë³‘ì›ëª… ì§ì ‘ í‘œê¸° ê¸ˆì§€. ì§€ì—­ ë¬¸êµ¬ëŠ” í•„ìš” ì‹œ ë¬¸ì¥ í›„ë°˜ë¶€ì— ìì—°ìŠ¤ëŸ½ê²Œ(ì˜ˆ: â€œâ€” ì„œìš¸ ê°•ë‚¨â€ ë˜ëŠ” â€œì„œìš¸ ê°•ë‚¨ì—ì„œâ€).
# 5) ì „í™”/ê°€ê²©/ì´ë²¤íŠ¸/URL/ë‚´ë¶€ë§í¬ ì•”ì‹œ ê¸ˆì§€. ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ìÂ·ì´ëª¨ì§€Â·ì „ê°ê´„í˜¸ ì§€ì–‘.
# 6) í˜ë¥´ì†Œë‚˜(tone_persona)ê°€ ìˆìœ¼ë©´ ê° í›„ë³´ì˜ ì–´ì¡°/ê´€ì ì— ë°˜ì˜.

# ìƒì„± ì§€ì¹¨:
# - ì„¹ì…˜ ì „ê°œ(ì„œë¡ â†’ë‚´ì›â†’ê²€ì‚¬â†’íŒâ†’ì¹˜ë£Œâ†’ì²´í¬í¬ì¸íŠ¸â†’ë§ˆë¬´ë¦¬) ê°€ìš´ë° í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ì••ì¶•í•´ ì œëª©ì—ì„œ ê¸°ëŒ€ ë‚´ìš©ì„ ëª…í™•íˆ ì•”ì‹œí•˜ì„¸ìš”.
# - [content_outline/summary]ì˜ ì¹´í…Œê³ ë¦¬/ì¦ìƒ/ì§„ë£Œ/ì¹˜ë£Œ ì¤‘ ê²€ìƒ‰ ì˜ë„ì— ê°€ì¥ ìœ íš¨í•œ 1ê°œë¥¼ ì„ íƒí•´ í¬í•¨í•˜ì„¸ìš”.
# - ì§€ì—­(city, district, region_phrase)ì´ ìˆìœ¼ë©´ ë§¥ë½ìƒ ìì—°ìŠ¤ëŸ¬ìš¸ ë•Œë§Œ ì œëª© í›„ë°˜ë¶€ì— ë§ë¶™ì´ì„¸ìš”.
# - í›„ë³´ë§ˆë‹¤ â€˜angleâ€™ì— í˜ë¥´ì†Œë‚˜/ì„¹ì…˜ ë°˜ì˜ ê´€ì ì„ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”(ì˜ˆ: â€œê´€ë¦¬í˜• í˜ë¥´ì†Œë‚˜: ì‚¬í›„ê´€ë¦¬/ì¬ë‚´ì› ê°„ê²© ê°•ì¡°â€).

# ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ(ì •í™•íˆ ì´ êµ¬ì¡° ì‚¬ìš©):
# {
#   "candidates": [
#     {"title":"...", "angle":"í˜ë¥´ì†Œë‚˜/ì„¹ì…˜ ë°˜ì˜ ê´€ì  ìš”ì•½"},
#     {"title":"...", "angle":"..."}
#   ],
#   "selected": {"title":"...", "why_best":"ì„ ì • ì´ìœ (ê°„ë‹¨)"}
# }

# ì…ë ¥ plan:
# """

# EMBEDDED_EVAL_PROMPT = """
# ë‹¤ìŒì€ ì¹˜ê³¼ ë¸”ë¡œê·¸ ì œëª© í›„ë³´ë“¤ì…ë‹ˆë‹¤. ê·œì¹™ì„ ë‹¤ì‹œ í™•ì¸í•˜ê³  ê·¸ì¤‘ ìµœì  1ê°œë¥¼ ì„ íƒí•˜ì„¸ìš”.

# ì„ íƒ ê¸°ì¤€(ìš”ì•½):
# - ì˜ë£Œê´‘ê³  ì¤€ìˆ˜(ê³¼ì¥/ë‹¨ì •/ê°€ê²©/ì „í™”/URL/ë³‘ì›ëª… ê¸ˆì§€)
# - ê²€ìƒ‰ì˜ë„ ì í•©ì„±(ì¹´í…Œê³ ë¦¬/ì¦ìƒ/ì§„ë£Œ/ì¹˜ë£Œ ì¤‘ 1ê°œ í•µì‹¬í‚¤ì›Œë“œ í¬í•¨, ë‚˜ì—´ ê¸ˆì§€)
# - ëª…í™•ì„±/êµ¬ì²´ì„±(í™˜ì ê´€ì  ê¸°ëŒ€ì´ë“ ì•”ì‹œ)
# - ì§€ì—­ ë¬¸êµ¬ëŠ” í›„ë°˜ë¶€ ìì—°ìŠ¤ëŸ¬ì›€(ìˆì„ ë•Œë§Œ)
# - ê¸¸ì´ ì ì •(ê¶Œì¥ 22~38ì Â· í—ˆìš© 18~42ì)

# ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ:
# {
#   "selected": {"title":"...", "why_best":"ì„ ì • ì´ìœ (ê°„ë‹¨)"}
# }

# í›„ë³´:
# """


def _load_text(path: Path) -> str:
    if path.exists():
        return path.read_text(encoding="utf-8")
    # return fallback
    raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")


# -----------------------
# í”Œëœâ†’ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
# -----------------------

def _get(d: Dict[str, Any], path: str, default=None):
    cur = d
    for k in path.split("."):
        if isinstance(cur, dict) and k in cur:
            cur = cur[k]
        else:
            return default
    return cur


def extract_context(plan: Dict[str, Any]) -> Dict[str, Any]:
    ctx = {
        "hospital_name": _get(plan, "context_vars.hospital_name", ""),
        "category": _get(plan, "context_vars.category", ""),
        "city": _get(plan, "context_vars.city", ""),
        "district": _get(plan, "context_vars.district", ""),
        "region_phrase": _get(plan, "context_vars.region_phrase", ""),
        "must_include_one_of": _get(plan, "title_plan.must_include_one_of", []),
        "must_not_include": _get(plan, "title_plan.must_not_include", []),
        "guidance": _get(plan, "title_plan.guidance", ""),
        "tone": _get(plan, "title_plan.tone", ""),
        "representative_persona": plan.get("representative_persona", ""),
        "sections": _get(plan, "content_plan.sections", {}),
    }
    return ctx


def build_generation_prompt(plan: Dict[str, Any], N: int) -> str:
    # tpl = _load_text(GEN_PROMPT_PATH, EMBEDDED_GEN_PROMPT)
    tpl = _load_text(GEN_PROMPT_PATH)
    # plan JSONì€ ê·¸ëŒ€ë¡œ ë¶™ì´ë˜, ë¶ˆí•„ìš” ê³µë°± ì¶•ì†Œ
    plan_min = json.dumps(plan, ensure_ascii=False)
    return tpl.replace("{N}", str(N)).rstrip() + "\n" + plan_min


def build_evaluation_prompt(candidates_json: Dict[str, Any]) -> str:
    # tpl = _load_text(EVAL_PROMPT_PATH, EMBEDDED_EVAL_PROMPT)
    tpl = _load_text(EVAL_PROMPT_PATH)
    return tpl.rstrip() + "\n" + json.dumps(candidates_json, ensure_ascii=False)


# -----------------------
# í›„ë³´ ìƒì„± & ì„ íƒ
# -----------------------

def generate_candidates(plan: Dict[str, Any], N: int = 5) -> Dict[str, Any]:
    prompt = build_generation_prompt(plan, N)
    sys_dir = (
        "You are an assistant that outputs ONLY valid JSON. No prose. No markdown fences.\n"
        "Return ONLY the JSON object per schema."
    )
    full_prompt = f"{sys_dir}\n\n{prompt}"
    raw = gem.generate(full_prompt)
    obj = _parse_json(raw) or {"candidates": [], "selected": {"title": "", "why_best": ""}}

    # ìµœì†Œ ìŠ¤í‚¤ë§ˆ ë³´ì •
    if not isinstance(obj.get("candidates"), list):
        obj["candidates"] = []
    obj.setdefault("selected", {"title": "", "why_best": ""})

    # ì •ë¦¬/í´ë¦°ì—…
    hospital_name = _get(plan, "context_vars.hospital_name", "")
    cleaned: List[Dict[str, str]] = []
    for c in obj["candidates"]:
        title = _clean(str(c.get("title", "")))
        angle = _clean(str(c.get("angle", "")))
        if not title:
            continue
        if _contains_hospital(title, hospital_name):
            continue
        if _violates_forbidden(title):
            continue
        cleaned.append({"title": title, "angle": angle})

    obj["candidates"] = cleaned[:N]
    # selectedëŠ” í‰ê°€ ë‹¨ê³„ì—ì„œ í™•ì •
    obj["selected"] = {"title": "", "why_best": ""}
    return obj


def select_best(plan: Dict[str, Any], candidates_obj: Dict[str, Any]) -> Dict[str, Any]:
    # ê¸¸ì´/ê¸ˆì§€ì–´ 1ì°¨ í•„í„°ë§ + ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ê²ƒì€ ì œì™¸
    hospital = _get(plan, "context_vars.hospital_name", "")
    filt = []
    for c in candidates_obj.get("candidates", []):
        t = c.get("title", "")
        if not _len_ok(t):
            continue
        if _contains_hospital(t, hospital):
            continue
        if _violates_forbidden(t):
            continue
        filt.append(c)

    cand_obj = {"candidates": filt or candidates_obj.get("candidates", [])}

    prompt = build_evaluation_prompt(cand_obj)
    sys_dir = (
        "You are an assistant that outputs ONLY valid JSON. No prose. No markdown fences.\n"
        "Return ONLY the JSON object per schema."
    )
    full = f"{sys_dir}\n\n{prompt}"
    raw = gem.generate(full)
    sel = _parse_json(raw) or {"selected": {"title": "", "why_best": ""}}

    # ë³´ì •: selected ëˆ„ë½ ì‹œ ì²« í›„ë³´ ì‚¬ìš©
    if not isinstance(sel.get("selected"), dict):
        sel["selected"] = {"title": "", "why_best": ""}
    if not sel["selected"].get("title") and cand_obj.get("candidates"):
        sel["selected"] = {"title": cand_obj["candidates"][0]["title"], "why_best": "ìµœì†Œ ê·œì¹™ ì¶©ì¡± ë° ëª…í™•ì„±"}

    return sel


# -----------------------
# ì €ì¥
# -----------------------

def save_outputs(mode: str, result: Dict[str, Any], meta: Dict[str, Any]) -> Tuple[Path, Path]:
    out_dir = Path(f"test_logs/{mode}/{_today()}")
    _ensure_dir(out_dir)
    ts = _now()
    out_path = out_dir / f"{ts}_title.json"
    log_path = out_dir / f"{ts}_title_log.json"
    out_path.write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
    log_path.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")
    return out_path, log_path


# -----------------------
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# -----------------------

def run(plan: Optional[Dict[str, Any]] = None, plan_path: Optional[str | Path] = None, mode: str = DEF_MODE, N: int = 5) -> Dict[str, Any]:
    plan_obj = load_plan(plan=plan, plan_path=plan_path, mode=mode)

    # í›„ë³´ ìƒì„±
    cand_obj = generate_candidates(plan_obj, N=N)

    # ëª¨ë¸ ì„ íƒ
    sel_obj = select_best(plan_obj, cand_obj)

    # ìµœì¢… ê²°ê³¼ ìŠ¤í‚¤ë§ˆ ì¡°ë¦½
    final = {
        "candidates": cand_obj.get("candidates", []),
        "selected": sel_obj.get("selected", {"title": "", "why_best": ""}),
    }

    # ì €ì¥ ë©”íƒ€
    meta = {
        "mode": mode,
        "timestamp": _now(),
        "plan_source": plan_obj.get("meta", {}).get("source_log", ""),
        "plan_snapshot": plan_obj,  # ì¶”í›„ ë””ë²„ê¹…ìš©
    }

    out, log = save_outputs(mode, final, meta)
    print(f"âœ… Title ì €ì¥: {out}")
    print(f"ğŸ§¾ ë¡œê·¸ ì €ì¥: {log}")
    return final

def run(plan: Optional[Dict[str, Any]] = None, plan_path: Optional[str | Path] = None, mode: str = DEF_MODE, N: int = 5) -> Dict[str, Any]:
    plan_obj = load_plan(plan=plan, plan_path=plan_path, mode=mode)

    # í›„ë³´ ìƒì„±
    cand_obj = generate_candidates(plan_obj, N=N)

    # ëª¨ë¸ ì„ íƒ
    sel_obj = select_best(plan_obj, cand_obj)

    # ìµœì¢… ê²°ê³¼ ìŠ¤í‚¤ë§ˆ ì¡°ë¦½
    final = {
        "candidates": cand_obj.get("candidates", []),
        "selected": sel_obj.get("selected", {"title": "", "why_best": ""}),
    }

    # ì‚¬ìš© ë°ì´í„° ë¡œê·¸ìš© ì¶”ì¶œ
    used_data = {
        "category": _get(plan_obj, "context_vars.category", ""),
        "city": _get(plan_obj, "context_vars.city", ""),
        "district": _get(plan_obj, "context_vars.district", ""),
        "region_phrase": _get(plan_obj, "context_vars.region_phrase", ""),
        "representative_persona": plan_obj.get("representative_persona", ""),
        "section_summaries": {k: v.get("summary", "") for k, v in _get(plan_obj, "content_plan.sections", {}).items()},
    }

    # ì €ì¥ ë©”íƒ€
    meta = {
        "mode": mode,
        "timestamp": _now(),
        "plan_source": plan_obj.get("meta", {}).get("source_log", ""),
        "plan_snapshot": plan_obj,  # ì¶”í›„ ë””ë²„ê¹…ìš©
        "used_data": used_data,     # ì œëª© ìƒì„± ì‹œ ì°¸ê³ í•œ ì£¼ìš” ë°ì´í„°
    }

    out, log = save_outputs(mode, final, meta)
    print(f"âœ… Title ì €ì¥: {out}")
    print(f"ğŸ§¾ ë¡œê·¸ ì €ì¥: {log}")
    print(f"ğŸ“Œ ì‚¬ìš© ë°ì´í„°: {json.dumps(used_data, ensure_ascii=False, indent=2)}")
    return final


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="TitleAgent â€” plan ê¸°ë°˜ ì œëª© í›„ë³´ ìƒì„± ë° ìµœì¢… ì„ íƒ")
    parser.add_argument("--mode", default=DEF_MODE, choices=["test", "use"], help="ë¡œê·¸ ì €ì¥ ëª¨ë“œ")
    parser.add_argument("--plan", default="", help="plan JSON ê²½ë¡œ(ë¯¸ì§€ì • ì‹œ ìµœì‹  íŒŒì¼ ìë™ íƒìƒ‰)")
    parser.add_argument("--num", type=int, default=5, help="ì œëª© í›„ë³´ ê°œìˆ˜")
    args = parser.parse_args()

    plan_path = args.plan if args.plan else None
    run(plan_path=plan_path, mode=args.mode, N=args.num)
